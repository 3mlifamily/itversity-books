{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Sqoop – Getting Started and Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get started with sqoop to get data from relational databases such as MySQL, Postgres etc into HDFS.\n",
    "* Introduction to Sqoop\n",
    "* Preview of MySQL in our labs\n",
    "* Connectivity to Database using Sqoop\n",
    "* Sqoop List Commands\n",
    "* Running queries in MySQL using Sqoop eval\n",
    "* Simple Sqoop Import\n",
    "* Sqoop Execution Life Cycle\n",
    "* Managing Directories\n",
    "\n",
    "### Introduction to Sqoop\n",
    "Let us get an overview of Sqoop.\n",
    "* It is command line tool to copy data between relational data sources to HDFS and vice versa\n",
    "* It is developed in Java\n",
    "* We will be using Sqoop 1.4.x as part of the course.\n",
    "* You can access Sqoop Documentation here – [Sqoop User Guide (v1.4.6)](https://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html)\n",
    "* Important Sqoop topics for the certification are sqoop-import, sqoop-export, sqoop-eval, sqoop-list-databases, sqoop-list-tables and sqoop-help\n",
    "* To check the version of sqoop use the command <mark>sqoop version</mark>\n",
    "* For import, the source is typically a relational database and target is HDFS\n",
    "* For export source is HDFS and target is the relational database\n",
    "* Data is copied using map reduce jobs\n",
    "\n",
    "### Preview of MySQL in our labs\n",
    "In our environment, we will be practicing Sqoop by copying data between MySQL and HDFS. Hence it is important to understand details about MySQL.\n",
    "* A demo is given using one of our Big Data Clusters. But you can use any other cluster to which you have access to.\n",
    "* You typically have to connect to Gateway Node in the cluster and from that node you should be able to connect to relational database – to perform Sqoop Import or Export.\n",
    "* Preview of MySQL\n",
    "    * Hostname: ms.itversity.com\n",
    "    * Several Databases for different data sets\n",
    "        * retail_db\n",
    "        * hr_db\n",
    "        * nyse_db\n",
    "    * Users\n",
    "        * retail_user\n",
    "        * hr_user\n",
    "        * nyse_user\n",
    "    * Password: itversity\n",
    "    \n",
    "***Login to MySQL Database***\n",
    "\n",
    "* To connect to the MySQL database using the username as <mark>mysql -u retail_user -h ms.itversity.com -p</mark>\n",
    "* -p will prompt for a password which is **itversity**\n",
    "\n",
    "## **Connectivity to Database using Sqoop**\n",
    "\n",
    "Almost all sqoop commands use connect string using.<mark>--connect</mark> It requires the following information:\n",
    "\n",
    "* Database type (MySQL, Oracle etc)\n",
    "* Hostname\n",
    "* Port number\n",
    "* Database Name (in case of MySQL)\n",
    "\n",
    "### Sqoop list commands\n",
    "Sqoop list, facilitate us to see a list of databases or tables from the database.\n",
    "* list-databases is used to list databases. In databases like Oracle 11g, it will list schemas.\n",
    "* list-tables is used to list tables from a given database (or schema in case of Oracle)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqoop list-databases \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306 \\\n",
    "  --username retail_user \\\n",
    "  --password itversity\n",
    "\n",
    "sqoop list-tables \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306/retail_db \\\n",
    "  --username retail_user \\\n",
    "  --password itversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running queries in MySQL using Sqoop eval\n",
    "Let us understand how we can run queries or commands in remote database. We will be using MySQL for the demo.\n",
    "* Running Queries – We can use eval to run queries on remote databases\n",
    "* Any valid SQL query or command can be run using sqoop eval. It is primarily used to load or query log tables while running Sqoop jobs at regular intervals.\n",
    "* We can issue commands such as select, insert, update, delete etc.\n",
    "* The user which is used to connect to the database should have required privileges on underlying tables\n",
    "* We can even invoke stored procedures."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqoop eval \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306/retail_db \\\n",
    "  --username retail_user \\\n",
    "  --password itversity \\\n",
    "  --query \"SELECT * FROM order_items LIMIT 10\"\n",
    "\n",
    "sqoop eval \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306/retail_db \\\n",
    "  --username retail_user \\\n",
    "  --password itversity \\\n",
    "  --query \"INSERT INTO orders VALUES (100000, '2017-10-31 00:00:00.0', 100000, 'DUMMY')\"\n",
    "\n",
    "sqoop eval \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306/retail_export \\\n",
    "  --username retail_user \\\n",
    "  --password itversity \\\n",
    "  --query \"CREATE TABLE dummy (i INT)\"\n",
    "\n",
    "sqoop eval \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306/retail_export \\\n",
    "  --username retail_user \\\n",
    "  --password itversity \\\n",
    "  --query \"INSERT INTO dummy VALUES (1)\"\n",
    "\n",
    "sqoop eval \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306/retail_export \\\n",
    "  --username retail_user \\\n",
    "  --password itversity \\\n",
    "  --query \"SELECT * FROM dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Sqoop Import\n",
    "Let us copy data from one table in MySQL to HDFS and understand how it works.\n",
    "* sqoop import is the main command\n",
    "* We need <mark>--connect</mark> to pass the connect string\n",
    "* We need to specify username and password to authenticate to the database\n",
    "* We need to specify a table name that needs to be copied\n",
    "* We also need to specify target location in HDFS (either by using <mark>--target-dir</mark> or <mark>--warehouse-dir</mark>)\n",
    "* We can use <mark>--target-dir</mark> to copy data to the path specified, whereas <mark>--warehouse-dir</mark> creates a directory with the name of the table and then copy the data into it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqoop import \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306/retail_db \\\n",
    "  --username retail_user \\\n",
    "  --password itversity \\\n",
    "  --table order_items \\\n",
    "  --warehouse-dir /user/dgadiraju/sqoop_import/retail_db"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqoop import \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306/retail_db \\\n",
    "  --username retail_user \\\n",
    "  --password itversity \\\n",
    "  --table order_items \\\n",
    "  --target-dir /user/dgadiraju/sqoop_import/retail_db/order_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sqoop Execution Life Cycle\n",
    "Here is the execution lifecycle of Sqoop.\n",
    "* Connect to the source database and get metadata\n",
    "* Generate java file with metadata and compile to a jar file\n",
    "* Apply **boundaryvalsquery** to apply split logic, default 4\n",
    "* Use split boundaries to issue queries against the source database\n",
    "* Each thread will have a different connection to issue the query\n",
    "* Each thread will get a mutually exclusive subset of the data\n",
    "* Data will be written to HDFS in a separate file per thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Directories\n",
    "When we run Sqoop import we need to deal with different scenarios with respect to the target directory.\n",
    "* If the directory already exists, we might want to throw an exception or overwrite or append new data into it. We can achieve all three using different options.\n",
    "* By default, the sqoop import fails if the target directory already exists\n",
    "* A directory can be overwritten by using <mark>--delete-target-dir</mark>\n",
    "* Data can be appended to existing directories by saying <mark>--append</mark>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqoop import \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306/retail_db \\\n",
    "  --username retail_user \\\n",
    "  --password itversity \\\n",
    "  --table order_items \\\n",
    "  --warehouse-dir /user/dgadiraju/sqoop_import/retail_db \\\n",
    "  --num-mappers 1 \\\n",
    "  --delete-target-dir\n",
    "\n",
    " sqoop import \\\n",
    "  --connect jdbc:mysql://ms.itversity.com:3306/retail_db \\\n",
    "  --username retail_user \\\n",
    "  --password itversity \\\n",
    "  --table order_items \\\n",
    "  --warehouse-dir /user/dgadiraju/sqoop_import/retail_db \\\n",
    "  --num-mappers 1 \\\n",
    "  --append"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - SQL",
   "language": "sql",
   "name": "apache_toree_sql"
  },
  "language_info": {
   "codemirror_mode": "text/x-sql",
   "file_extension": ".sql",
   "mimetype": "text/x-sql",
   "name": "sql",
   "pygments_lexer": "sql",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
